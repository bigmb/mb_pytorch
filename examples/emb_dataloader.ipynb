{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding generation using emb_dataloader which checks the path and verifies the file type and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some packages need async support in jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_pytorch.utils.generate_emb import EmbeddingGenerator\n",
    "from mb_utils.src.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon 01:30:17,637 INF Read data from yaml file: [{'data': {'from_datasets': 'CIFAR10', 'from_file': True, 'work_dir': '/home/malav/Des\n",
      "Mon 01:30:17,640 INF Data folder already exists. Using existing data folder :  /home/malav/Desktop/mb_packages/mb_pytorch/data/      \n",
      "Mon 01:30:17,645 INF Read data from yaml file: [{'data': {'from_datasets': 'CIFAR10', 'from_file': True, 'work_dir': '/home/malav/Des\n",
      "Mon 01:30:17,663 INF Read data from yaml file: [{'data': {'from_datasets': 'CIFAR10', 'from_file': True, 'work_dir': '/home/malav/Des\n",
      "Mon 01:30:17,666 INF transforms: [ToTensor(), RandomHorizontalFlip(p=0.5), RandomRotation(degrees=[-90.0, 90.0], interpolation=neares\n"
     ]
    }
   ],
   "source": [
    "emb = EmbeddingGenerator('../scripts/embeddings/gen_emb_all.yaml', logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon 01:30:17,677 INF Read data from yaml file: [{'data': {'from_datasets': 'CIFAR10', 'from_file': True, 'work_dir': '/home/malav/Des\n",
      "Mon 01:30:17,680 INF transforms: [ToTensor(), RandomHorizontalFlip(p=0.5), RandomRotation(degrees=[-90.0, 90.0], interpolation=neares\n",
      "50row [00:00, 34987.52row/s]\n",
      "Mon 01:30:17,688 INF Loaded dataframe from /home/malav/Desktop/mb_packages/mb_pytorch/data/csv/file_data.csv using asyncio           \n",
      "Mon 01:30:17,690 INF Data file: {'from_datasets': 'CIFAR10', 'from_file': True, 'work_dir': '/home/malav/Desktop/mb_packages/mb_pytor\n",
      "Mon 01:30:17,692 INF Data columns: Index(['image_path', 'image_type'], dtype='object')                                               \n",
      "Mon 01:30:17,693 INF Data will be split into train and validation according to train_file input : False                              \n",
      "Mon 01:30:17,695 INF If unnamed columns are present, they will be removed.                                                           \n",
      "Mon 01:30:17,696 INF If duplicate rows are present, they will be removed.                                                            \n",
      "Mon 01:30:17,697 INF Checking duplicates for the columns: ['image_path']                                                             \n",
      "Mon 01:30:17,698 INF No duplicates found                                                                                             \n",
      "Mon 01:30:17,699 INF Removing unnamed columns                                                                                        \n",
      "Mon 01:30:17,701 INF Columns : Index(['image_path', 'image_type'], dtype='object')                                                   \n",
      "Mon 01:30:17,703 INF Verifying paths                                                                                                 \n",
      "Mon 01:30:17,704 INF first path : /home/malav/Desktop/mb_packages/mb_pytorch/data/images1/img_0.jpg                                  \n",
      "Mon 01:30:17,707 INF self.data:     image_path  image_type                                     image_path_new  \\\n",
      "0    img_1.jpg    tr\n",
      "Mon 01:30:17,709 INF Length of data after removing invalid paths: 49                                                                 \n",
      "Mon 01:30:17,710 INF Verifying images                                                                                                \n"
     ]
    }
   ],
   "source": [
    "emb_loader = emb.data_emb_loader(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malav/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/malav/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Mon 01:30:18,306 INF Model set to resnet18                                                                                           \n",
      "Mon 01:30:18,394 INF Embedding generation started                                                                                    \n",
      "Mon 01:30:18,396 INF length of data: 13                                                                                              \n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 38.03it/s]/home/malav/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 13/13 [00:00<00:00, 39.89it/s]\n",
      "Mon 01:30:18,792 INF Embedding generation completed                                                                                  \n"
     ]
    }
   ],
   "source": [
    "final_emb = emb.generate_emb(emb_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49row [00:00, 22649.43row/s]\n",
      "Mon 01:30:38,302 INF Embeddings saved to /home/malav/Desktop/mb_packages/mb_pytorch/data/emb_wrangled_file.csv                       \n"
     ]
    }
   ],
   "source": [
    "emb.file_save(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malav/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/malav/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Mon 01:30:43,848 INF Model set to resnet18                                                                                           \n",
      "Mon 01:30:43,881 INF Embedding generation started                                                                                    \n",
      "Mon 01:30:43,883 INF length of data: 13                                                                                              \n",
      "100%|██████████| 13/13 [00:00<00:00, 69.35it/s]\n",
      "Mon 01:30:44,143 INF Embedding generation completed                                                                                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6066133 , 0.        , 0.01152018, ..., 0.23953357, 0.2776498 ,\n",
       "        0.        ],\n",
       "       [1.2507732 , 0.        , 0.0868827 , ..., 1.0830673 , 0.02329071,\n",
       "        0.        ],\n",
       "       [1.116545  , 0.        , 0.04925364, ..., 0.29010677, 0.79718137,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.0967342 , 0.        , 0.02135782, ..., 0.17740084, 0.42222133,\n",
       "        0.        ],\n",
       "       [1.334017  , 0.        , 0.15939952, ..., 0.7924853 , 0.66509014,\n",
       "        0.        ],\n",
       "       [0.91792893, 0.        , 0.01271179, ..., 0.        , 0.6245557 ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.generate_emb(emb_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_pandas.src.dfload import load_any_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49row [00:00, 8465.31row/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                                                             0\n",
       "image_path                                                img_1.jpg\n",
       "image_type                                                 training\n",
       "image_path_new    /home/malav/Desktop/mb_packages/mb_pytorch/dat...\n",
       "img_path_check                                                 True\n",
       "img_verify                                                     True\n",
       "embedding         [1.1758252382278442, 0.0, 0.0, 1.0482074022293...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = load_any_df('../data/emb_wrangled_file.csv')\n",
    "t1.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
